# =============================================================================
# Cloud Build: Document Intelligence Backend API
# =============================================================================
# Automated CI/CD pipeline for Cloud Run deployment with GitHub integration.
#
# Triggers:
#   - develop branch → dev environment
#   - master branch → prod environment
#
# Manual deployment:
#   gcloud builds submit --config cloudbuild.yaml
#   gcloud builds submit --config cloudbuild.yaml --substitutions=_ENV=prod,_SECRET_SUFFIX=-prod
#
# Timeline: ~5-7 minutes
# =============================================================================

options:
  machineType: 'E2_HIGHCPU_8'
  diskSizeGb: 100
  logging: CLOUD_LOGGING_ONLY
  substitutionOption: 'ALLOW_LOOSE'

timeout: '1800s'

steps:
  # Step 1: Run automated tests
  # - Development: smoke tests only (fast)
  # - Production: full test suite
  - name: 'python:3.12-slim'
    id: 'run-tests'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "Installing UV package manager..."
        curl -LsSf https://astral.sh/uv/install.sh | sh
        export PATH="/root/.cargo/bin:$$PATH"

        echo "Installing dependencies..."
        uv sync --frozen

        if [ "${_ENV}" = "prod" ]; then
          echo "Running full test suite (production)..."
          uv run pytest tests/ -v --asyncio-mode=auto --tb=short || exit 1
          echo "All production tests passed!"
        else
          echo "Running smoke tests (development)..."
          uv run pytest tests/ -v -m "smoke" --asyncio-mode=auto --tb=short || true
          echo "Smoke tests completed!"
        fi

  # Step 2: Build Docker image
  - name: 'gcr.io/cloud-builders/docker'
    id: 'build-image'
    args:
      - 'build'
      - '--platform=linux/amd64'
      - '-t'
      - '${_REGION}-docker.pkg.dev/$PROJECT_ID/document-intelligence/backend-api:$BUILD_ID'
      - '-t'
      - '${_REGION}-docker.pkg.dev/$PROJECT_ID/document-intelligence/backend-api:${_ENV}-latest'
      - '-t'
      - '${_REGION}-docker.pkg.dev/$PROJECT_ID/document-intelligence/backend-api:latest'
      - '.'
    waitFor: ['run-tests']

  # Step 3: Push all image tags to Artifact Registry
  - name: 'gcr.io/cloud-builders/docker'
    id: 'push-image'
    args:
      - 'push'
      - '--all-tags'
      - '${_REGION}-docker.pkg.dev/$PROJECT_ID/document-intelligence/backend-api'
    waitFor: ['build-image']

  # Step 4: Deploy to Cloud Run (immediate 100% traffic)
  - name: 'gcr.io/cloud-builders/gcloud'
    id: 'deploy-to-cloudrun'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "Deploying to Cloud Run (${_ENV})..."

        gcloud run deploy ${_SERVICE_NAME} \
          --image=${_REGION}-docker.pkg.dev/$PROJECT_ID/document-intelligence/backend-api:$BUILD_ID \
          --region=${_REGION} \
          --platform=managed \
          --allow-unauthenticated \
          --memory=${_MEMORY} \
          --cpu=${_CPU} \
          --concurrency=${_CONCURRENCY} \
          --max-instances=${_MAX_INSTANCES} \
          --timeout=60 \
          --port=8080 \
          --add-cloudsql-instances=${_CLOUD_SQL_INSTANCE} \
          --update-env-vars=ENVIRONMENT=${_ENV},GCP_PROJECT_ID=$PROJECT_ID,LOG_LEVEL=${_LOG_LEVEL},LOG_FORMAT=json,GCS_BUCKET_NAME=${_GCS_BUCKET_NAME},FRONTEND_DOMAIN=${_FRONTEND_DOMAIN},MAX_FILE_SIZE=${_MAX_FILE_SIZE},CLOUD_SQL_INSTANCE=${_CLOUD_SQL_INSTANCE},USE_CLOUD_SQL_CONNECTOR=true,CLOUD_SQL_IP_TYPE=PUBLIC,DATABASE_NAME=${_DATABASE_NAME},DATABASE_USER=${_DATABASE_USER} \
          --remove-env-vars=PRODUCTION_CORS_ORIGINS,ALLOWED_FILE_TYPES \
          --update-secrets=JWT_SECRET_KEY=JWT_SECRET_KEY${_SECRET_SUFFIX}:latest,DATABASE_PASSWORD=DATABASE_PASSWORD${_SECRET_SUFFIX}:latest \
          || exit 1

        echo "Deployment successful!"
    waitFor: ['push-image']

  # Step 5: Health check
  - name: 'gcr.io/cloud-builders/gcloud'
    id: 'health-check'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "Running health checks..."

        # Get service URL
        SERVICE_URL=$$(gcloud run services describe ${_SERVICE_NAME} --region=${_REGION} --format="value(status.url)")
        echo "Service URL: $$SERVICE_URL"

        # Wait for service to be ready
        echo "Waiting 15 seconds for service to initialize..."
        sleep 15

        # Test health endpoint
        echo "Testing /health endpoint..."
        HTTP_STATUS=$$(curl -s -o /dev/null -w "%{http_code}" "$$SERVICE_URL/health")
        if [ "$$HTTP_STATUS" -eq 200 ]; then
          echo "Health check passed! (HTTP $$HTTP_STATUS)"
        else
          echo "Health check failed! (HTTP $$HTTP_STATUS)"
          exit 1
        fi

        # Test status endpoint
        echo "Testing /status endpoint..."
        HTTP_STATUS=$$(curl -s -o /dev/null -w "%{http_code}" "$$SERVICE_URL/status")
        if [ "$$HTTP_STATUS" -eq 200 ]; then
          echo "Status check passed! (HTTP $$HTTP_STATUS)"
        else
          echo "Status check failed! (HTTP $$HTTP_STATUS)"
          exit 1
        fi

        echo ""
        echo "Health checks passed!"
        echo "Deployment complete!"
        echo "Environment: ${_ENV}"
        echo "Service URL: $$SERVICE_URL"
    waitFor: ['deploy-to-cloudrun']

# Substitution variables
# Override these via Cloud Build triggers or --substitutions flag
substitutions:
  # Core settings
  _ENV: 'dev'
  _REGION: 'us-central1'
  _SERVICE_NAME: 'document-intelligence-api-dev'
  _SECRET_SUFFIX: ''  # Empty for dev, '-prod' for production

  # GCP settings
  _GCS_BUCKET_NAME: 'biz2bricks-dev-v1-document-store'
  _SERVICE_ACCOUNT: '727735128283-compute@developer.gserviceaccount.com'

  # Cloud SQL settings
  _CLOUD_SQL_INSTANCE: 'biz2bricks-dev-v1:us-central1:doc-intelligence-db'
  _DATABASE_NAME: 'doc_intelligence'
  _DATABASE_USER: 'postgres'

  # CORS and domains
  _FRONTEND_DOMAIN: 'dev.biztobricks.com'
  _PRODUCTION_CORS_ORIGINS: '["https://dev.biztobricks.com","http://localhost:3000"]'

  # Resource limits
  _LOG_LEVEL: 'DEBUG'
  _MEMORY: '1Gi'
  _CPU: '1'
  _CONCURRENCY: '80'
  _MAX_INSTANCES: '5'

  # Application settings
  _MAX_FILE_SIZE: '52428800'
  _ALLOWED_FILE_TYPES: '["pdf", "xlsx", "xls", "csv"]'

# Store built images in Artifact Registry
images:
  - '${_REGION}-docker.pkg.dev/$PROJECT_ID/document-intelligence/backend-api:$BUILD_ID'
  - '${_REGION}-docker.pkg.dev/$PROJECT_ID/document-intelligence/backend-api:${_ENV}-latest'
  - '${_REGION}-docker.pkg.dev/$PROJECT_ID/document-intelligence/backend-api:latest'

# Tags for build organization
tags:
  - 'backend-api'
  - '${_ENV}'

# =============================================================================
# Trigger Configuration Reference
# =============================================================================
#
# Development Trigger (develop branch):
#   Name: backend-api-dev-deploy
#   Branch: ^develop$
#   Substitutions: (use defaults)
#
# Production Trigger (master branch):
#   Name: backend-api-prod-deploy
#   Branch: ^master$
#   Substitutions:
#     _ENV: prod
#     _SERVICE_NAME: document-intelligence-api-prod
#     _SECRET_SUFFIX: -prod
#     _LOG_LEVEL: INFO
#     _MAX_INSTANCES: 10
#     _FRONTEND_DOMAIN: biztobricks.com
#     _PRODUCTION_CORS_ORIGINS: ["https://biztobricks.com","https://www.biztobricks.com"]
#
# =============================================================================
