# ===========================================
# Unified Cloud Build Configuration
# Document Intelligence API - Cloud Run Deployment
# ===========================================
#
# Single configuration for all environments with branch-based settings.
#
# Triggers:
#   - develop branch → development environment
#   - master/main branch → production environment
#
# Usage:
#   # Manual deployment (development)
#   gcloud builds submit --config cloudbuild.yaml
#
#   # Manual deployment (production)
#   gcloud builds submit --config cloudbuild.yaml \
#     --substitutions=_ENVIRONMENT=production,_SERVICE_NAME=document-intelligence-api,...
#
#   # Or use the deploy script:
#   ./deploy.sh --deploy --env production
#
# Timeline: ~5-7 minutes

options:
  machineType: 'E2_HIGHCPU_8'
  diskSizeGb: 100
  logging: CLOUD_LOGGING_ONLY
  substitutionOption: 'ALLOW_LOOSE'

timeout: '1800s'

# Load secrets from Secret Manager
# Development: no suffix, Production: -prod suffix
availableSecrets:
  secretManager:
    - versionName: projects/$PROJECT_ID/secrets/JWT_SECRET_KEY${_SECRET_SUFFIX}/versions/latest
      env: JWT_SECRET_KEY
    - versionName: projects/$PROJECT_ID/secrets/DATABASE_PASSWORD${_SECRET_SUFFIX}/versions/latest
      env: DATABASE_PASSWORD

steps:
  # Step 1: Run automated tests
  # - Development: smoke tests only (fast)
  # - Production: full test suite
  - name: 'python:3.12-slim'
    id: 'run-tests'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "Installing UV package manager..."
        curl -LsSf https://astral.sh/uv/install.sh | sh
        export PATH="/root/.cargo/bin:$PATH"

        echo "Installing dependencies..."
        uv sync --frozen

        if [ "${_ENVIRONMENT}" = "production" ]; then
          echo "Running full test suite (production)..."
          uv run pytest tests/ -v --asyncio-mode=auto --tb=short || exit 1
          echo "All production tests passed!"
        else
          echo "Running smoke tests (development)..."
          uv run pytest tests/ -v -m "smoke" --asyncio-mode=auto --tb=short || exit 1
          echo "Smoke tests passed!"
        fi

  # Step 2: Build Docker image
  - name: 'gcr.io/cloud-builders/docker'
    id: 'build-image'
    args:
      - 'build'
      - '--platform=linux/amd64'
      - '-t'
      - 'gcr.io/$PROJECT_ID/${_SERVICE_NAME}:$COMMIT_SHA'
      - '-t'
      - 'gcr.io/$PROJECT_ID/${_SERVICE_NAME}:${_ENVIRONMENT}-latest'
      - '-t'
      - 'gcr.io/$PROJECT_ID/${_SERVICE_NAME}:latest'
      - '.'
    waitFor: ['run-tests']

  # Step 3: Push all image tags to Container Registry
  - name: 'gcr.io/cloud-builders/docker'
    id: 'push-image'
    args:
      - 'push'
      - '--all-tags'
      - 'gcr.io/$PROJECT_ID/${_SERVICE_NAME}'
    waitFor: ['build-image']

  # Step 4: Deploy to Cloud Run (immediate 100% traffic)
  - name: 'gcr.io/cloud-builders/gcloud'
    id: 'deploy-to-cloudrun'
    entrypoint: 'bash'
    secretEnv: ['JWT_SECRET_KEY', 'DATABASE_PASSWORD']
    args:
      - '-c'
      - |
        echo "Deploying to Cloud Run (${_ENVIRONMENT})..."

        gcloud run deploy ${_SERVICE_NAME} \
          --image=gcr.io/$PROJECT_ID/${_SERVICE_NAME}:$COMMIT_SHA \
          --region=${_REGION} \
          --platform=managed \
          --allow-unauthenticated \
          --memory=${_MEMORY} \
          --cpu=${_CPU} \
          --concurrency=${_CONCURRENCY} \
          --max-instances=${_MAX_INSTANCES} \
          --timeout=60 \
          --port=8080 \
          --service-account=${_SERVICE_ACCOUNT} \
          --add-cloudsql-instances=${_CLOUD_SQL_INSTANCE} \
          --set-env-vars="ENVIRONMENT=${_ENVIRONMENT},GCP_PROJECT_ID=$PROJECT_ID,LOG_LEVEL=${_LOG_LEVEL},LOG_FORMAT=json,GCS_BUCKET_NAME=${_GCS_BUCKET_NAME},FRONTEND_DOMAIN=${_FRONTEND_DOMAIN},PRODUCTION_CORS_ORIGINS=${_PRODUCTION_CORS_ORIGINS},MAX_FILE_SIZE=${_MAX_FILE_SIZE},ALLOWED_FILE_TYPES=${_ALLOWED_FILE_TYPES},CLOUD_SQL_INSTANCE=${_CLOUD_SQL_INSTANCE},USE_CLOUD_SQL_CONNECTOR=true,CLOUD_SQL_IP_TYPE=PUBLIC,DATABASE_NAME=${_DATABASE_NAME},DATABASE_USER=${_DATABASE_USER}" \
          --update-secrets=JWT_SECRET_KEY=JWT_SECRET_KEY${_SECRET_SUFFIX}:latest,DATABASE_PASSWORD=DATABASE_PASSWORD${_SECRET_SUFFIX}:latest

        echo "Deployment successful!"
    waitFor: ['push-image']

  # Step 5: Health check
  - name: 'gcr.io/cloud-builders/curl'
    id: 'health-check'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "Running health checks..."

        # Get service URL
        SERVICE_URL=$(gcloud run services describe ${_SERVICE_NAME} --region=${_REGION} --format="value(status.url)")
        echo "Service URL: $SERVICE_URL"

        # Wait for service to be ready
        echo "Waiting 15 seconds for service to initialize..."
        sleep 15

        # Test health endpoint
        echo "Testing /health endpoint..."
        curl -f -s "$SERVICE_URL/health" | python3 -m json.tool || exit 1

        # Test status endpoint
        echo "Testing /status endpoint..."
        curl -f -s "$SERVICE_URL/status" | python3 -m json.tool || exit 1

        echo "Health checks passed!"
        echo ""
        echo "Deployment complete!"
        echo "Environment: ${_ENVIRONMENT}"
        echo "Service URL: $SERVICE_URL"
    waitFor: ['deploy-to-cloudrun']

# Substitution variables
# Override these via Cloud Build triggers or --substitutions flag
substitutions:
  # Core settings
  _REGION: 'us-central1'
  _SERVICE_NAME: 'document-intelligence-api-dev-v2'
  _ENVIRONMENT: 'development'
  _SECRET_SUFFIX: ''  # Empty for dev, '-prod' for production

  # GCP settings
  _GCS_BUCKET_NAME: 'biz2bricks-dev-v1-document-store'
  _SERVICE_ACCOUNT: '727735128283-compute@developer.gserviceaccount.com'

  # Cloud SQL settings
  _CLOUD_SQL_INSTANCE: 'biz-to-bricks-dev:us-central1:doc-intelligence-db'
  _DATABASE_NAME: 'doc_intelligence'
  _DATABASE_USER: 'postgres'

  # CORS and domains
  _FRONTEND_DOMAIN: 'dev.biztobricks.com'
  _PRODUCTION_CORS_ORIGINS: '["https://dev.biztobricks.com","http://localhost:3000"]'

  # Resource limits
  _LOG_LEVEL: 'INFO'
  _MEMORY: '1Gi'
  _CPU: '1'
  _CONCURRENCY: '80'
  _MAX_INSTANCES: '5'

  # Application settings
  _MAX_FILE_SIZE: '52428800'
  _ALLOWED_FILE_TYPES: '["pdf", "xlsx", "xls", "csv"]'

# Store built images in Container Registry
images:
  - 'gcr.io/$PROJECT_ID/${_SERVICE_NAME}:$COMMIT_SHA'
  - 'gcr.io/$PROJECT_ID/${_SERVICE_NAME}:${_ENVIRONMENT}-latest'
  - 'gcr.io/$PROJECT_ID/${_SERVICE_NAME}:latest'

# Tags for build organization
tags:
  - 'document-intelligence-api-v2'
  - 'cloud-run-deployment'

# ===========================================
# Trigger Configuration Reference
# ===========================================
#
# Development Trigger (develop branch):
#   Name: develop-deploy
#   Branch: ^develop$
#   Substitutions: (use defaults)
#
# Production Trigger (master branch):
#   Name: production-deploy
#   Branch: ^master$
#   Substitutions:
#     _SERVICE_NAME: document-intelligence-api
#     _ENVIRONMENT: production
#     _SECRET_SUFFIX: -prod
#     _LOG_LEVEL: INFO
#     _MAX_INSTANCES: 10
#     _FRONTEND_DOMAIN: biztobricks.com
#     _PRODUCTION_CORS_ORIGINS: ["https://biztobricks.com","https://www.biztobricks.com"]
#
